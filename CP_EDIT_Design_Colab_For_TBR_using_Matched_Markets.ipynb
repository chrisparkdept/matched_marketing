{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfbuo9GAOOyg"
      },
      "source": [
        "# Design of an experiment with TBR using Matched Markets\n",
        "\n",
        "Please note that this colab is for TBR Geo experiments only.\n",
        "\n",
        "\n",
        "Using this colab, you can create a geoexperiment design for a client using TBR in combination with Matched Markets. In the following we will use the acronyms TBR for Time Based Regression and MM for Matched Markets. For a general introduction to TBR and MM, please refer to the TBR [paper](https://research.google/pubs/pub45950/), the MM [paper](https://research.google/pubs/pub48983/), and this [introduction](http://www.unofficialgoogledatascience.com/2016/06/estimating-causal-effects-using-geo.html) to geo experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PeLu1eAGuC7B"
      },
      "outputs": [],
      "source": [
        "#@title Load the libraries needed for the design\n",
        "\n",
        "BAZEL_VERSION = '3.0.0'\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/{BAZEL_VERSION}/bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!chmod +x bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!./bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh\n",
        "!sudo apt-get install python3-dev python3-setuptools git\n",
        "!git clone https://github.com/google/matched_markets\n",
        "!python3 -m pip install ./matched_markets\n",
        "!pip install colorama\n",
        "!pip install gspread-dataframe\n",
        "\n",
        "\n",
        "\"\"\"Loading the necessary python modules.\"\"\"\n",
        "import altair as alt\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from scipy import stats\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "import gspread\n",
        "import warnings\n",
        "from colorama import Fore, Style\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google import auth as google_auth\n",
        "from google.colab import auth\n",
        "from google.colab import data_table\n",
        "from google.colab import widgets\n",
        "from google.colab import drive\n",
        "from matched_markets.methodology.common_classes import GeoAssignment\n",
        "from matched_markets.methodology import geoeligibility\n",
        "from matched_markets.methodology import tbrmmdata\n",
        "from matched_markets.methodology import tbrmmdesignparameters\n",
        "from matched_markets.methodology import tbrmmdiagnostics\n",
        "from matched_markets.methodology import tbrmatchedmarkets\n",
        "from matched_markets.methodology import tbrmmdesign\n",
        "from matched_markets.methodology import utils\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_PXNPQe2uPEl"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter the trix url for the sheet file containing the Client Sales Data:\n",
        "#@markdown The spreadsheet should contain the mandatory columns:\n",
        "#@markdown * date: date in the format YYYY-MM-DD\n",
        "#@markdown * geo: the number which identifies the geo\n",
        "#@markdown * response: variable on which you want to measure incrementality\n",
        "#@markdown (e.g. sales, transactions)\n",
        "#@markdown * cost: variable used as spend proxy (e.g. ad spend)\n",
        "\n",
        "#@markdown Other columns can be present in the spreadsheet.\n",
        "\n",
        "#@markdown Spreadsheet URL containing the geo level response and spend data\n",
        "client_sales_table = \"https://docs.google.com/spreadsheets/d/13AsE5wGq7IKYlwvU_sOkr-XTy02QMcU81O6Kcnhln2g/edit?gid=0#gid=0\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Leave the following field empty if you don't want to add constraint to the geo_eligibility\n",
        "geo_eligibility_table = \"\" #@param {type:\"string\"}\n",
        "auth.authenticate_user()\n",
        "creds, _ = google_auth.default()\n",
        "gc = gspread.authorize(creds)\n",
        "wks = gc.open_by_url(client_sales_table).sheet1\n",
        "data = wks.get_all_values()\n",
        "headers = data.pop(0)\n",
        "geo_level_time_series = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "geo_level_time_series[\"date\"] = pd.to_datetime(geo_level_time_series[\"date\"])\n",
        "for colname in [\"response\", \"geo\", \"cost\"]:\n",
        "  geo_level_time_series[colname] = pd.to_numeric(geo_level_time_series[colname])\n",
        "\n",
        "num_geos = geo_level_time_series[\"geo\"].nunique()\n",
        "\n",
        "if not geo_eligibility_table:\n",
        "  geo_eligibility = None\n",
        "else:\n",
        "  wks = gc.open_by_url(geo_eligibility_table).sheet1\n",
        "  data = wks.get_all_values()\n",
        "  headers = data.pop(0)\n",
        "  geo_eligibility = pd.DataFrame(data, columns=headers)\n",
        "  for colname in [\"geo\", \"control\", \"treatment\", \"exclude\"]:\n",
        "    geo_eligibility[colname] = pd.to_numeric(geo_eligibility[colname])\n",
        "  # set missing geos in geo_eligibility as eligible for any assignment\n",
        "  geo_eligibility = utils.default_geo_assignment(geo_level_time_series,\n",
        "                                                 geo_eligibility)\n",
        "  geo_eligibility = geoeligibility.GeoEligibility(geo_eligibility)\n",
        "  geo_eligibility.data.index = pd.to_numeric(geo_eligibility.data.index,\n",
        "                                             downcast=\"integer\").astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_frequency(data: pd.DataFrame, date_index: str,\n",
        "                    series_index: str) -> str:\n",
        "    data = data.copy().set_index([series_index, date_index])\n",
        "    data = data.sort_values(by=[date_index, series_index])\n",
        "    series_names = data.index.get_level_values(series_index).unique().tolist()\n",
        "    series_frequencies = []\n",
        "    for series in series_names:\n",
        "        observed_times = data.loc[series].index.get_level_values(date_index)\n",
        "        n_steps = len(observed_times)\n",
        "        if n_steps > 1:\n",
        "            # Key fix: Use .days to get integer days instead of dtype conversion\n",
        "            time_diffs = (observed_times[1:] - observed_times[:-1]).days\n",
        "            min_frequency = np.min(time_diffs)\n",
        "            series_frequencies.append(min_frequency)\n",
        "\n",
        "    if not series_frequencies:\n",
        "        raise ValueError(\"At least one series with >1 observation must exist.\")\n",
        "\n",
        "    if not all(freq == series_frequencies[0] for freq in series_frequencies):\n",
        "        raise ValueError(\"Inconsistent frequencies across series.\")\n",
        "\n",
        "    frequency_map = {1: 'D', 7: 'W'}\n",
        "    try:\n",
        "        return frequency_map[series_frequencies[0]]\n",
        "    except KeyError:\n",
        "        raise ValueError(f\"Unsupported frequency: {series_frequencies[0]} days.\")"
      ],
      "metadata": {
        "id": "mVvnmLpyiD_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 Google LLC.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ============================================================================\n",
        "\"\"\"TBR Matched Markets preanalysis.\n",
        "\"\"\"\n",
        "import copy\n",
        "import itertools\n",
        "from typing import Generator, List, Set, Text, TypeVar\n",
        "\n",
        "from matched_markets.methodology import geoeligibility\n",
        "from matched_markets.methodology import heapdict\n",
        "from matched_markets.methodology import tbrmmdata\n",
        "from matched_markets.methodology import tbrmmdesign\n",
        "from matched_markets.methodology import tbrmmdesignparameters\n",
        "from matched_markets.methodology import tbrmmdiagnostics\n",
        "from matched_markets.methodology import tbrmmscore\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import special as scipy_special\n",
        "# Copyright 2020 Google LLC.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ============================================================================\n",
        "\"\"\"TBR Matched Markets: Class representing a TBR Design Score.\n",
        "\"\"\"\n",
        "import collections\n",
        "from typing import Union\n",
        "import dataclasses\n",
        "\n",
        "from matched_markets.methodology import tbrmmdiagnostics\n",
        "\n",
        "Number = Union[int, float]\n",
        "TBRMMDiagnostics = tbrmmdiagnostics.TBRMMDiagnostics\n",
        "Scoring = collections.namedtuple('Scoring', [\n",
        "    'corr_test', 'aa_test', 'bb_test', 'dw_test', 'corr', 'inv_required_impact'\n",
        "])\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class TBRMMScore:\n",
        "  \"\"\"Class representing a TBR design score.\n",
        "\n",
        "  TBRMMScore defines a score which can be used to sort TBRMMDesign. The scoring\n",
        "  function is a NamedTuple with properties:\n",
        "\n",
        "  - corr_test, aa_test, bb_test, dw_test which are True if the corresponding\n",
        "    diagnostics tests pass. These are prioritize when sorting TBRMMDesign, i.e.\n",
        "    a design which does not pass one of these tests will be worse than a design\n",
        "    which pass all of them.\n",
        "\n",
        "  - corr is the correlation between the current design treatment and\n",
        "    control group.\n",
        "\n",
        "  - inv_required_impact is the inverse of the minimum lift which we need to\n",
        "    generate for a significant result. So, 1/required_impact can be thought of\n",
        "    as the inverse of the minimum detectable iROAS for a budget of 1$.\n",
        "\n",
        "\n",
        "  The idea of using the logical result of the tests is due to the fact that it\n",
        "  could happen that none of the designs searched pass at least 1 of these tests\n",
        "  (it does not have to be the same tests for all designs). To be constructive,\n",
        "  we still want to output the best design that can be found, but we will\n",
        "  highlight/flag the risk of running an experiment which fails one of the tests.\n",
        "  Knowing which test failed can be useful as well to understand what is \"wrong\".\n",
        "\n",
        "  In future, the binary outcome for the tests can be replaced by a p-value or\n",
        "  similar continuous metrics. For example. the aa test result already provide\n",
        "  the probability of a false positive result (if the result is positive).\n",
        "\n",
        "  Attributes:\n",
        "    diag: a TBRMMDiagnostics object.\n",
        "  \"\"\"\n",
        "\n",
        "  diag: TBRMMDiagnostics  # design diagnostics\n",
        "  _score = None  # score of the corresponding design\n",
        "\n",
        "  def __post_init__(self):\n",
        "    if self.diag.x is None:\n",
        "      raise ValueError('No Control time series was specified')\n",
        "    if self.diag.corr is None:\n",
        "      corr = self.diag.corr\n",
        "    if self.diag.required_impact is None:\n",
        "      impact = self.diag.required_impact\n",
        "\n",
        "  def __lt__(self, other: 'TBRMMScore'):\n",
        "    return self.score < other.score\n",
        "\n",
        "  @property\n",
        "  def score(self):\n",
        "    if self._score is None:\n",
        "          \"\"\"Score of the design.\"\"\"\n",
        "      # Handle potential None values in test results\n",
        "          corr_test = int(self.diag.corr_test) if self.diag.corr_test is not None else 0\n",
        "          aatest_ok = int(self.diag.aatest.test_ok) if (self.diag.aatest and self.diag.aatest.test_ok is not None) else 0\n",
        "          bbtest_ok = int(self.diag.bbtest.test_ok) if (self.diag.bbtest and self.diag.bbtest.test_ok is not None) else 0\n",
        "          dwtest_ok = int(self.diag.dwtest.test_ok) if (self.diag.dwtest and self.diag.dwtest.test_ok is not None) else 0\n",
        "          corr = round(self.diag.corr, 2) if self.diag.corr is not None else 0.0\n",
        "          required_impact = self.diag.required_impact if self.diag.required_impact is not None else 1e-6  # Avoid division by zero\n",
        "\n",
        "          self._score = Scoring(\n",
        "              corr_test,\n",
        "              aatest_ok,\n",
        "              bbtest_ok,\n",
        "              dwtest_ok,\n",
        "              corr,\n",
        "              1 / required_impact\n",
        "          )\n",
        "    return self._score\n",
        "\n",
        "  @score.setter\n",
        "  def score(self, value: Scoring):\n",
        "    self._score = value\n",
        "\n",
        "TBRMMDesignParameters = tbrmmdesignparameters.TBRMMDesignParameters\n",
        "TBRMMDiagnostics = tbrmmdiagnostics.TBRMMDiagnostics\n",
        "TBRMMData = tbrmmdata.TBRMMData\n",
        "TBRMMDesign = tbrmmdesign.TBRMMDesign\n",
        "TBRMMScore = TBRMMScore\n",
        "GeoID = Text\n",
        "GeoIndex = int\n",
        "DictKey = TypeVar('DictKey', str, int, float)\n",
        "\n",
        "\n",
        "class TBRMatchedMarkets:\n",
        "  \"\"\"TBR Matched Market preanalysis.\n",
        "\n",
        "  Attributes:\n",
        "    data: The TBRMMData object.\n",
        "    parameters: The TBRMMDesignParameters object.\n",
        "    geo_req_impact: Required minimum incremental impact for each individual geo.\n",
        "  \"\"\"\n",
        "\n",
        "  data: TBRMMData\n",
        "  parameters: TBRMMDesignParameters\n",
        "  geo_req_impact: pd.Series\n",
        "\n",
        "  def __init__(self, data: TBRMMData, parameters: TBRMMDesignParameters):\n",
        "    \"\"\"Initialize a TBRMatchedMarkets object.\n",
        "\n",
        "    Args:\n",
        "      data: A TBRMMData object.\n",
        "      parameters: a TBRMMDesignParameters object.\n",
        "    \"\"\"\n",
        "\n",
        "    def estimate_required_impact(y):\n",
        "      return TBRMMDiagnostics(y,\n",
        "                              parameters).estimate_required_impact(\n",
        "                                  parameters.rho_max)\n",
        "    # Consider only the most recent n_pretest_max time points\n",
        "    data.df = data.df.iloc[:, -parameters.n_pretest_max:]\n",
        "    # Calculate the required impact estimates for each geo.\n",
        "    geo_req_impact = data.df.apply(estimate_required_impact, axis=1)\n",
        "\n",
        "    self.geo_req_impact = geo_req_impact\n",
        "    self.data = data\n",
        "    self.parameters = parameters\n",
        "\n",
        "  @property\n",
        "  def geos_over_budget(self) -> Set[GeoID]:\n",
        "    \"\"\"Identify geos which do not satisfy the max ad spend budget condition.\"\"\"\n",
        "    if self.parameters.budget_range is not None:\n",
        "      max_impact = self.parameters.budget_range[1] * self.parameters.iroas\n",
        "      geo_impact = self.geo_req_impact\n",
        "      geos = set(geo_impact.index[geo_impact > max_impact])\n",
        "    else:\n",
        "      geos = set()\n",
        "    return geos\n",
        "\n",
        "  @property\n",
        "  def geos_too_large(self) -> Set[GeoID]:\n",
        "    \"\"\"Identify geos which do not satisfy the maximum geo share condition.\"\"\"\n",
        "    if self.parameters.treatment_share_range is not None:\n",
        "      max_trt_share = self.parameters.treatment_share_range[1]\n",
        "      geo_share = self.data.geo_share\n",
        "      geos = set(geo_share.index[geo_share > max_trt_share])\n",
        "    else:\n",
        "      geos = set()\n",
        "    return geos\n",
        "\n",
        "  @property\n",
        "  def geos_must_include(self) -> Set[GeoID]:\n",
        "    \"\"\"Set of geos that must be included in each design.\"\"\"\n",
        "    geo_assignments = self.data.geo_eligibility.get_eligible_assignments()\n",
        "    return geo_assignments.all - geo_assignments.x\n",
        "\n",
        "  @property\n",
        "  def geos_within_constraints(self) -> Set[GeoID]:\n",
        "    \"\"\"Set of geos that are within the geo-specific constraints.\n",
        "\n",
        "    Returns:\n",
        "      Geos that are assignable to control or treatment but not over budget nor\n",
        "      too large, plus those that must be assigned to the treatment or control\n",
        "      group (even if over budget or too large). If the maximum number is\n",
        "      specified, the geos with the highest impact on budget are chosen.\n",
        "    \"\"\"\n",
        "    geos_exceed_size = self.geos_too_large | self.geos_over_budget\n",
        "    geos = (self.data.assignable - geos_exceed_size) | self.geos_must_include\n",
        "    n_geos_max = self.parameters.n_geos_max\n",
        "    if n_geos_max is not None and len(geos) > n_geos_max:\n",
        "      geos_with_max_impact = list(\n",
        "          self.geo_req_impact.sort_values(ascending=False).index)\n",
        "      geos_in_order = list(geo for geo in geos_with_max_impact if geo in geos)\n",
        "      geos = set(geos_in_order[:n_geos_max])\n",
        "    return geos\n",
        "\n",
        "  @property\n",
        "  def geo_assignments(self) -> geoeligibility.GeoAssignments:\n",
        "    \"\"\"Return the possible geo assignments.\"\"\"\n",
        "\n",
        "    geos_included = self.geos_within_constraints\n",
        "\n",
        "    # Order geos in the order of implied budget size ('expensive' first).\n",
        "    geos_in_order = list(self.geo_req_impact.index)\n",
        "    geo_index = [geo for geo in geos_in_order if geo in geos_included]\n",
        "\n",
        "    self.data.geo_index = geo_index\n",
        "    return self.data.geo_assignments\n",
        "\n",
        "  def treatment_group_size_range(self) -> range:\n",
        "    \"\"\"Range from smallest to largest possible treatment group size.\"\"\"\n",
        "    n_treatment_min = max(1, len(self.geo_assignments.t_fixed))\n",
        "    n_treatment_max = len(self.geo_assignments.t)\n",
        "    if not self.geo_assignments.cx | self.geo_assignments.c_fixed:\n",
        "      # No geos left outside the group 't', so reserve at least one geo for the\n",
        "      # control group.\n",
        "      n_treatment_max -= 1\n",
        "\n",
        "    treatment_geos_range = self.parameters.treatment_geos_range\n",
        "    if treatment_geos_range is None:\n",
        "      n_geos_from, n_geos_to = (n_treatment_min, n_treatment_max)\n",
        "    else:\n",
        "      n_geos_from = max(treatment_geos_range[0], n_treatment_min)\n",
        "      n_geos_to = min(treatment_geos_range[1], n_treatment_max)\n",
        "\n",
        "    return range(n_geos_from, n_geos_to + 1)\n",
        "\n",
        "  def _control_group_size_generator(\n",
        "      self,\n",
        "      n_treatment_geos: int) -> Generator[int, None, None]:\n",
        "    \"\"\"Acceptable control group sizes, given treatment group size.\n",
        "\n",
        "    Args:\n",
        "      n_treatment_geos: Number of treatment geos.\n",
        "\n",
        "    Yields:\n",
        "      Control group sizes that agree with the range and ratio constraints.\n",
        "    \"\"\"\n",
        "    n_control_min = max(1, len(self.geo_assignments.c_fixed))\n",
        "    n_control_max = len(self.geo_assignments.c)\n",
        "\n",
        "    control_geos_range = self.parameters.control_geos_range\n",
        "    if control_geos_range is None:\n",
        "      n_geos_from, n_geos_to = (n_control_min, n_control_max)\n",
        "    else:\n",
        "      n_geos_from = max(control_geos_range[0], n_control_min)\n",
        "      n_geos_to = min(control_geos_range[1], n_control_max)\n",
        "\n",
        "    if self.parameters.geo_ratio_tolerance is None:\n",
        "      yield from range(n_geos_from, n_geos_to + 1)\n",
        "    else:\n",
        "      geo_tol_max = 1.0 + self.parameters.geo_ratio_tolerance\n",
        "      geo_tol_min = 1.0 / geo_tol_max\n",
        "      for n_control_geos in range(n_geos_from, n_geos_to + 1):\n",
        "        geo_ratio = n_control_geos / n_treatment_geos\n",
        "        if geo_ratio >= geo_tol_min and geo_ratio <= geo_tol_max:\n",
        "          yield n_control_geos\n",
        "\n",
        "  def treatment_group_generator(\n",
        "      self,\n",
        "      n: int) -> Generator[Set[GeoIndex], None, None]:\n",
        "    \"\"\"Generates all possible treatment groups of given size.\n",
        "\n",
        "    The indices will generated in the order from smallest to largest, e.g.,\n",
        "    choosing n=2 geos out of {0, 1, 2, 3} will yield the sequence {0, 1}, {0,\n",
        "    2}, {0, 3}, {1, 2}, {1, 3}, {2, 3}. The indices refer to geos from largest\n",
        "    to smallest, i.e., geo 0 is the largest, 4 is the smallest. The fixed geos\n",
        "    will be added to the set.\n",
        "\n",
        "    Args:\n",
        "      n: Size of the treatment group.\n",
        "\n",
        "    Raises:\n",
        "      ValueError if n is not positive.\n",
        "\n",
        "    Yields:\n",
        "      Sets of geo indices, of length n each. If there are not enough geos\n",
        "      available, does not yield anything.\n",
        "    \"\"\"\n",
        "    if n <= 0:\n",
        "      raise ValueError('Treatment group size n must be positive')\n",
        "\n",
        "    fixed_treatment_geos = self.geo_assignments.t_fixed\n",
        "    varying_treatment_geos = self.geo_assignments.t - fixed_treatment_geos\n",
        "    n_remaining = n - len(fixed_treatment_geos)\n",
        "    if n_remaining == 0 and fixed_treatment_geos:\n",
        "      yield fixed_treatment_geos  # pytype: disable=bad-return-type\n",
        "    elif n_remaining > 0:\n",
        "      it = itertools.combinations(varying_treatment_geos, n_remaining)\n",
        "      for treatment_geos_combination in it:\n",
        "        treatment_group = fixed_treatment_geos | set(treatment_geos_combination)\n",
        "        yield treatment_group  # pytype: disable=bad-return-type\n",
        "\n",
        "  def control_group_generator(\n",
        "      self,\n",
        "      treatment_group: Set[GeoIndex]) -> Generator[Set[GeoIndex], None, None]:\n",
        "    \"\"\"Iterates over control geo combinations, given a treatment group.\n",
        "\n",
        "    Args:\n",
        "      treatment_group: Set of treatment geos. The sequence of control groups is\n",
        "      constructed from the remaining geos.\n",
        "\n",
        "    Yields:\n",
        "      Sets of geo indices representing control groups. If there are not enough\n",
        "      geos available, does not yield anything.\n",
        "    \"\"\"\n",
        "    if not treatment_group:\n",
        "      raise ValueError('Treatment group must not be empty')\n",
        "\n",
        "    # The treatment group must be a subset of the available treatment geos.\n",
        "    invalid_geo_indices = treatment_group - self.geo_assignments.t\n",
        "    if invalid_geo_indices:\n",
        "      geos = [str(geo_index) for geo_index in sorted(invalid_geo_indices)]\n",
        "      raise ValueError(\n",
        "          'Invalid treatment geo indices: ' + ', '.join(geos))\n",
        "\n",
        "    # The fixed control geos are those that belong to either 'c_fixed' or 'ct'.\n",
        "    # The geos in the group 'ct' must be assigned to control or treatment, but\n",
        "    # not excluded.\n",
        "    ct_geos_not_in_treatment = self.geo_assignments.ct - treatment_group\n",
        "    fixed_control_geos = self.geo_assignments.c_fixed | ct_geos_not_in_treatment\n",
        "    possible_control_geos = self.geo_assignments.c - treatment_group\n",
        "\n",
        "    # The 'varying control geos' can be in the groups 'cx' or 'ctx' only.\n",
        "    varying_control_geos = possible_control_geos - fixed_control_geos\n",
        "\n",
        "    n_treatment_geos = len(treatment_group)\n",
        "\n",
        "    for n_control_geos in self._control_group_size_generator(n_treatment_geos):\n",
        "      n_remaining = n_control_geos - len(fixed_control_geos)\n",
        "      if n_remaining == 0 and fixed_control_geos:\n",
        "        yield fixed_control_geos  # pytype: disable=bad-return-type\n",
        "      elif n_remaining > 0:\n",
        "        # If n_remaining > len(varying_control_geos), the generator will not\n",
        "        # return anything.\n",
        "        it = itertools.combinations(varying_control_geos, n_remaining)\n",
        "        for control_geos in it:\n",
        "          control_group = fixed_control_geos | set(control_geos)\n",
        "          yield control_group  # pytype: disable=bad-return-type\n",
        "\n",
        "  def count_max_designs(self) -> int:\n",
        "    \"\"\"Count (fast) how many designs there are at most.\n",
        "\n",
        "    Only the group sizes and their ratio is used as a constraint.\n",
        "\n",
        "    Returns:\n",
        "      Maximum number of designs under the constraint of the geo eligibility\n",
        "      matrix, and the geo group sizes and allowed ratios.\n",
        "    \"\"\"\n",
        "    n_t_fixed = len(self.geo_assignments.t_fixed)\n",
        "    n_c_fixed = len(self.geo_assignments.c_fixed)\n",
        "    n_cx = len(self.geo_assignments.cx)\n",
        "    n_tx = len(self.geo_assignments.tx)\n",
        "    n_ct = len(self.geo_assignments.ct)\n",
        "    n_ctx = len(self.geo_assignments.ctx)\n",
        "    trt_sizes = set(self.treatment_group_size_range())\n",
        "    # Pre-compute the control sizes to avoid repetition within the loop.\n",
        "    control_group_sizes = {}\n",
        "    for n_trt in trt_sizes:\n",
        "      group_sizes = set(self._control_group_size_generator(n_trt))\n",
        "      control_group_sizes[n_trt] = group_sizes\n",
        "    n_designs = 0\n",
        "    # Split the space into the subspaces cx, tx, ct, ctx.\n",
        "    comb = scipy_special.comb\n",
        "    for i_ct in range(1 + n_ct):\n",
        "      n1 = comb(n_ct, i_ct, exact=True)\n",
        "      for i_tx in range(1 + n_tx):\n",
        "        n2 = comb(n_tx, i_tx, exact=True)\n",
        "        for i_ctx in range(1 + n_ctx):\n",
        "          n_trt = n_t_fixed + i_tx + i_ctx + i_ct\n",
        "          if n_trt in trt_sizes:\n",
        "            ctl_sizes = control_group_sizes[n_trt]\n",
        "            n3 = comb(n_ctx, i_ctx, exact=True)\n",
        "            for i_cx in range(1 + n_cx):\n",
        "              n4 = comb(n_cx, i_cx, exact=True)\n",
        "              for i_cctx in range(1 + n_ctx - i_ctx):\n",
        "                n_ctl = n_c_fixed + i_cx + i_cctx + (n_ct - i_ct)\n",
        "                if n_ctl in ctl_sizes:\n",
        "                  n5 = comb(n_ctx - i_ctx, i_cctx, exact=True)\n",
        "                  n_designs += n1 * n2 * n3 * n4 * n5\n",
        "    return n_designs\n",
        "\n",
        "  def exhaustive_search(self) -> List[TBRMMDesign]:\n",
        "    \"\"\"Search the design space for acceptable designs, within the constraints.\n",
        "\n",
        "    Returns:\n",
        "      the set of feasible designs found given the design parameters,\n",
        "        with their corresponding treatment/control groups and score.\n",
        "    \"\"\"\n",
        "    treatment_share_range = self.parameters.treatment_share_range\n",
        "    budget_range = self.parameters.budget_range\n",
        "\n",
        "    # Do not store patterns when we have the last treatment pattern size.\n",
        "    skip_this_trt_group_size = list(self.treatment_group_size_range()).pop()\n",
        "    skip_treatment_geo_patterns = []\n",
        "\n",
        "    results = heapdict.HeapDict(size=self.parameters.n_designs)\n",
        "\n",
        "    def skip_if_subset(geos: Set[GeoIndex]) -> bool:\n",
        "      \"\"\"Check if one of the stored geo patterns is a subset of the geos.\n",
        "\n",
        "      Args:\n",
        "        geos: Set of geo indices.\n",
        "\n",
        "      Returns:\n",
        "        bool: True if one of the stored groups is a subset of the geos.\n",
        "      \"\"\"\n",
        "      for p in skip_treatment_geo_patterns:\n",
        "        if set(p).issubset(geos):\n",
        "          return True\n",
        "      return False\n",
        "\n",
        "    volume_tol = self.parameters.volume_ratio_tolerance\n",
        "    if volume_tol is not None:\n",
        "      tol_min = 1.0 / (1.0 + volume_tol)\n",
        "      tol_max = 1.0 + volume_tol\n",
        "\n",
        "    treatment_group_sizes = self.treatment_group_size_range()\n",
        "    for treatment_group_size in treatment_group_sizes:\n",
        "\n",
        "      # Treatment groups are saved for the purpose of the inclusion check.\n",
        "      save_treatment_groups = (treatment_group_size != skip_this_trt_group_size)\n",
        "\n",
        "      treatment_groups = self.treatment_group_generator(treatment_group_size)\n",
        "      for treatment_group in treatment_groups:\n",
        "        treatment_share = self.data.aggregate_geo_share(treatment_group)\n",
        "        if treatment_share_range is not None:\n",
        "          # Skip this treatment group if the group implies too low or high share\n",
        "          # of response volume.\n",
        "          if (treatment_share > treatment_share_range[1] or\n",
        "              treatment_share < treatment_share_range[0]):\n",
        "            continue\n",
        "        elif skip_if_subset(treatment_group):\n",
        "          # If the group is a superset of a group that we already know has too\n",
        "          # high a share or budget, then skip this group too.\n",
        "          continue\n",
        "        y = self.data.aggregate_time_series(treatment_group)\n",
        "        diag = TBRMMDiagnostics(y, self.parameters)\n",
        "        req_impact = diag.estimate_required_impact(self.parameters.rho_max)\n",
        "        req_budget = req_impact / self.parameters.iroas\n",
        "        if budget_range is not None:\n",
        "          # If the budget is too high, skip this treatment group.\n",
        "          if req_budget > budget_range[1]:\n",
        "            if save_treatment_groups:\n",
        "              # We skip all treatment groups that are a superset of a treatment\n",
        "              # group that has too high an estimated budget.\n",
        "              skip_treatment_geo_patterns.append(treatment_group)\n",
        "              continue\n",
        "            # If the budget is too low, skip this treatment group.\n",
        "          elif req_budget < budget_range[0]:\n",
        "            continue\n",
        "        control_groups = self.control_group_generator(treatment_group)\n",
        "        for control_group in control_groups:\n",
        "          if volume_tol is not None:\n",
        "            control_share = self.data.aggregate_geo_share(control_group)\n",
        "            xy_share = control_share / treatment_share\n",
        "            if xy_share > tol_max or xy_share < tol_min:\n",
        "              continue\n",
        "          diag.x = self.data.aggregate_time_series(control_group)\n",
        "          corr = diag.corr  # pylint: disable=unused-variable\n",
        "          req_impact = diag.required_impact\n",
        "          req_budget = req_impact / self.parameters.iroas\n",
        "          if (budget_range is not None and (self._constraint_not_satisfied(\n",
        "              req_budget, budget_range[0], budget_range[1]))):\n",
        "            continue\n",
        "\n",
        "          # deepcopy is needed otherwise diag.corr gets overwritten, and so\n",
        "          # it will not be equal to diag.score.score.corr for some reason\n",
        "          design_score = TBRMMScore(copy.deepcopy(diag))\n",
        "          score = design_score.score\n",
        "          if budget_range is not None:\n",
        "            # If the budget was specified then we use the inverse of the\n",
        "            # minimum detectable iROAS for the max. budget as the last value\n",
        "            # in the scoring, instead of using the same for a budget of 1$\n",
        "            iroas = req_impact / budget_range[1]\n",
        "            design_score.score = score._replace(inv_required_impact=1 / iroas)\n",
        "\n",
        "          # deepcopy is needed otherwise diag.corr gets overwritten, and so\n",
        "          # it will not be equal to diag.score.score.corr for some reason\n",
        "          design = TBRMMDesign(\n",
        "              design_score, treatment_group, control_group,\n",
        "              copy.deepcopy(diag))\n",
        "          results.push(0, design)\n",
        "\n",
        "    self._search_results = results\n",
        "    return self.search_results()\n",
        "\n",
        "  def search_results(self):\n",
        "    \"\"\"Outputs the results of the exhaustive search in a friendly format.\n",
        "\n",
        "    Returns:\n",
        "      results: the set of feasible designs found given the design parameters,\n",
        "        with their corresponding treatment/control groups and score.\n",
        "\n",
        "    \"\"\"\n",
        "    result = self._search_results.get_result()\n",
        "    output_result = []\n",
        "    if result:\n",
        "      design = result[0]\n",
        "      # map from geo indices to geo IDs.\n",
        "      for d in design:\n",
        "        treatment_geos = {self.data.geo_index[x] for x in d.treatment_geos}\n",
        "        control_geos = {self.data.geo_index[x] for x in d.control_geos}\n",
        "        d.treatment_geos = treatment_geos\n",
        "        d.control_geos = control_geos\n",
        "        output_result.append(d)\n",
        "\n",
        "    return output_result\n",
        "\n",
        "  @staticmethod\n",
        "  def _constraint_not_satisfied(parameter_value: float,\n",
        "                                constraint_lower: float,\n",
        "                                constraint_upper: float) -> bool:\n",
        "    \"\"\"Checks if the parameter value is in the interval [constraint_lower, constraint_upper].\"\"\"\n",
        "    return (parameter_value < constraint_lower) | (\n",
        "        parameter_value > constraint_upper)\n",
        "\n",
        "  def design_within_constraints(self, treatment_geos: Set[GeoIndex],\n",
        "                                control_geos: Set[GeoIndex]):\n",
        "    \"\"\"Checks if a set of control/treatment geos passes all constraints.\n",
        "\n",
        "    Given a set of control and treatment geos we verify that some of their\n",
        "    metrics are within the bounds specified in TBRMMDesignParameters.\n",
        "\n",
        "    Args:\n",
        "      treatment_geos: Set of geo indices referring to the geos in treatment.\n",
        "      control_geos: Set of geo indices referring to the geos in control.\n",
        "\n",
        "    Returns:\n",
        "      False if any specified constraint is not satisfied.\n",
        "    \"\"\"\n",
        "    if self.parameters.volume_ratio_tolerance is not None:\n",
        "      volume_ratio = (\n",
        "          self.data.aggregate_geo_share(control_geos)/\n",
        "          self.data.aggregate_geo_share(treatment_geos))\n",
        "      if self._constraint_not_satisfied(\n",
        "          volume_ratio, 1 / (1 + self.parameters.volume_ratio_tolerance),\n",
        "          1 + self.parameters.volume_ratio_tolerance):\n",
        "        return False\n",
        "\n",
        "    if self.parameters.geo_ratio_tolerance is not None:\n",
        "      geo_ratio = len(control_geos) / len(treatment_geos)\n",
        "      if self._constraint_not_satisfied(\n",
        "          geo_ratio, 1 / (1 + self.parameters.geo_ratio_tolerance),\n",
        "          1 + self.parameters.geo_ratio_tolerance):\n",
        "        return False\n",
        "\n",
        "    if self.parameters.treatment_share_range is not None:\n",
        "      treatment_response_share = self.data.aggregate_geo_share(\n",
        "          treatment_geos) / self.data.aggregate_geo_share(\n",
        "              self.geo_assignments.all)\n",
        "      if self._constraint_not_satisfied(\n",
        "          treatment_response_share, self.parameters.treatment_share_range[0],\n",
        "          self.parameters.treatment_share_range[1]):\n",
        "        return False\n",
        "\n",
        "    if self.parameters.treatment_geos_range is not None:\n",
        "      num_treatment_geos = len(treatment_geos)\n",
        "      if self._constraint_not_satisfied(\n",
        "          num_treatment_geos, self.parameters.treatment_geos_range[0],\n",
        "          self.parameters.treatment_geos_range[1]):\n",
        "        return False\n",
        "\n",
        "    if self.parameters.control_geos_range is not None:\n",
        "      num_control_geos = len(control_geos)\n",
        "      if self._constraint_not_satisfied(num_control_geos,\n",
        "                                        self.parameters.control_geos_range[0],\n",
        "                                        self.parameters.control_geos_range[1]):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "  def greedy_search(self):\n",
        "    \"\"\"Searches the Matched Markets for a TBR experiment.\n",
        "\n",
        "    Uses a greedy hill climbing algorithm to provide recommended 'matched\n",
        "    markets' experimental group assignments that appear to lead to valid and\n",
        "    effective TBR models relative to the pretest period.  This is accomplished\n",
        "    by using a greedy hill climbing alogirhtm that alternates between two\n",
        "    routines:\n",
        "    1) Looks for the best set of control geos given the current\n",
        "       set of treatment geos.\n",
        "    2) Adds one new geo to the set of treatment geos given\n",
        "       the current control group.\n",
        "\n",
        "    See Au (2018) for more details.\n",
        "\n",
        "    Returns:\n",
        "      the set of feasible designs found given the design parameters,\n",
        "        with their corresponding treatment/control groups and score.\n",
        "    \"\"\"\n",
        "    budget_range = self.parameters.budget_range\n",
        "    results = heapdict.HeapDict(size=self.parameters.n_designs)\n",
        "\n",
        "    if self.parameters.treatment_geos_range is None:\n",
        "      n_treatment = len(self.geo_assignments.t)\n",
        "      max_treatment_size = n_treatment\n",
        "      n_remaining = len(self.geo_assignments.all) - n_treatment\n",
        "      if n_remaining == 0:\n",
        "        max_treatment_size = n_treatment - 1\n",
        "      self.parameters.treatment_geos_range = (1, max_treatment_size)\n",
        "    else:\n",
        "      max_treatment_size = self.parameters.treatment_geos_range[1]\n",
        "\n",
        "    if self.parameters.control_geos_range is None:\n",
        "      n_control = len(self.geo_assignments.c)\n",
        "      max_control_size = n_control\n",
        "      n_remaining = len(self.geo_assignments.all) - n_control\n",
        "      if n_remaining == 0:\n",
        "        max_control_size = n_control - 1\n",
        "      self.parameters.control_geos_range = (1, max_control_size)\n",
        "\n",
        "    kappa_0 = len(self.geo_assignments.t_fixed)\n",
        "    group_star_trt = {kappa_0: self.geo_assignments.t_fixed}\n",
        "    tmp_diag = TBRMMDiagnostics(np.random.normal(range(100)), self.parameters)\n",
        "    tmp_diag.x = list(range(len(tmp_diag.y)))\n",
        "    tmp_score = TBRMMScore(tmp_diag)\n",
        "    tmp_score.score = tmp_score.score._replace(\n",
        "        corr_test=0,\n",
        "        aa_test=0,\n",
        "        bb_test=0,\n",
        "        dw_test=0,\n",
        "        corr=0,\n",
        "        inv_required_impact=0)\n",
        "    score_star = {kappa_0: tmp_score}\n",
        "    group_ctl = self.geo_assignments.c\n",
        "    if kappa_0 == 0:\n",
        "      group_star_ctl = {kappa_0: group_ctl}\n",
        "      needs_matching = False\n",
        "    else:\n",
        "      group_star_ctl = {}\n",
        "      needs_matching = True\n",
        "\n",
        "    k = kappa_0\n",
        "    while (k < max_treatment_size) | (needs_matching):\n",
        "      # Find the best control group given the current treatment group\n",
        "      if needs_matching:\n",
        "        r_control = self.geo_assignments.c - (group_ctl | group_star_trt[k])\n",
        "        r_unassigned = (group_ctl & self.geo_assignments.x) - group_star_trt[k]\n",
        "\n",
        "        reassignable_geos = r_control | r_unassigned\n",
        "        treatment_time_series = self.data.aggregate_time_series(\n",
        "            group_star_trt[k])\n",
        "        current_design = TBRMMDiagnostics(treatment_time_series,\n",
        "                                          self.parameters)\n",
        "        current_design.x = self.data.aggregate_time_series(group_ctl)\n",
        "        current_score = TBRMMScore(current_design)\n",
        "\n",
        "        group_ctl_tmp = group_ctl\n",
        "        for geo in reassignable_geos:\n",
        "          neighboring_control_group = group_ctl.symmetric_difference([geo])\n",
        "          # we skip checking constraints for designs with less than the minimum\n",
        "          # number of treatment geos, or above the maximum number of control\n",
        "          # geos. Otherwise, we will never be able to augment the size of\n",
        "          # treatment (to reach a size which would pass the checks) or decrease\n",
        "          # the size of control\n",
        "          if (k >= self.parameters.treatment_geos_range[0]) and (\n",
        "              len(neighboring_control_group) <=\n",
        "              self.parameters.control_geos_range[1]):\n",
        "            if (not neighboring_control_group) or (\n",
        "                not self.design_within_constraints(group_star_trt[k],\n",
        "                                                   neighboring_control_group)):  # pytype: disable=wrong-arg-types\n",
        "              continue\n",
        "\n",
        "          neighbor_design = tbrmmdiagnostics.TBRMMDiagnostics(\n",
        "              treatment_time_series, self.parameters)\n",
        "          neighbor_design.x = self.data.aggregate_time_series(\n",
        "              neighboring_control_group)\n",
        "          req_impact = neighbor_design.required_impact\n",
        "          req_budget = req_impact / self.parameters.iroas\n",
        "          if (budget_range is not None) and (self._constraint_not_satisfied(\n",
        "              req_budget, budget_range[0], budget_range[1])):\n",
        "            continue\n",
        "\n",
        "          score = TBRMMScore(neighbor_design)\n",
        "          if score > current_score:\n",
        "            group_ctl_tmp = neighboring_control_group\n",
        "            current_score = score\n",
        "\n",
        "        if current_score > TBRMMScore(current_design):\n",
        "          group_ctl = group_ctl_tmp\n",
        "        else:\n",
        "          group_star_ctl[k] = group_ctl_tmp\n",
        "          score_star[k] = current_score\n",
        "          needs_matching = False\n",
        "      # add one geo to treatment given the current control group\n",
        "      elif k < max_treatment_size:\n",
        "        r_treatment = self.geo_assignments.t - group_star_trt[k]\n",
        "\n",
        "        current_score = copy.deepcopy(tmp_score)\n",
        "        group_trt = group_star_trt[k]\n",
        "        for geo in r_treatment:\n",
        "          augmented_treatment_group = group_star_trt[k].union([geo])\n",
        "          updated_control_group = group_star_ctl[k] - set([geo])\n",
        "          # see comment on lines 566-567 for the same if statement\n",
        "          if (k >= self.parameters.treatment_geos_range[0]) and (\n",
        "              len(updated_control_group) <=\n",
        "              self.parameters.control_geos_range[1]):\n",
        "            if (not updated_control_group) or (\n",
        "                not self.design_within_constraints(augmented_treatment_group,\n",
        "                                                   updated_control_group)):\n",
        "              continue\n",
        "          treatment_time_series = self.data.aggregate_time_series(\n",
        "              augmented_treatment_group)\n",
        "          neighbor_design = TBRMMDiagnostics(\n",
        "              treatment_time_series, self.parameters)\n",
        "          neighbor_design.x = self.data.aggregate_time_series(\n",
        "              updated_control_group)\n",
        "          req_impact = neighbor_design.required_impact\n",
        "          req_budget = req_impact / self.parameters.iroas\n",
        "          if (budget_range is not None) and (self._constraint_not_satisfied(\n",
        "              req_budget, budget_range[0], budget_range[1])):\n",
        "            continue\n",
        "          score = TBRMMScore(neighbor_design)\n",
        "          if score > current_score:\n",
        "            group_ctl = updated_control_group\n",
        "            group_trt = augmented_treatment_group\n",
        "            current_score = score\n",
        "\n",
        "        group_star_trt[k+1] = group_trt\n",
        "        k = k + 1\n",
        "        needs_matching = True\n",
        "\n",
        "    # if some geos are fixed to treatment, we did not check that the design\n",
        "    # with treatment group = {all geos fixed in treatment} and control group =\n",
        "    # {all geos that can be assigned to control} pass the diagnostic tests\n",
        "    if kappa_0 > 0:\n",
        "      diagnostic = TBRMMDiagnostics(\n",
        "          self.data.aggregate_time_series(group_star_trt[kappa_0]),\n",
        "          self.parameters)\n",
        "      diagnostic.x = self.data.aggregate_time_series(group_star_ctl[kappa_0])\n",
        "      req_impact = diagnostic.required_impact\n",
        "      req_budget = req_impact / self.parameters.iroas\n",
        "      if (not group_star_ctl[kappa_0]) or (not self.design_within_constraints(\n",
        "          group_star_trt[kappa_0], group_star_ctl[kappa_0])):\n",
        "        if (budget_range is not None) and (self._constraint_not_satisfied(\n",
        "            req_budget, budget_range[0], budget_range[1])):\n",
        "          group_star_trt.pop(kappa_0, None)\n",
        "          group_star_ctl.pop(kappa_0, None)\n",
        "          score_star.pop(kappa_0, None)\n",
        "\n",
        "    group_star_trt.pop(0, None)\n",
        "    group_star_ctl.pop(0, None)\n",
        "    score_star.pop(0, None)\n",
        "    for k in group_star_trt:\n",
        "      if self.design_within_constraints(group_star_trt[k], group_star_ctl[k]):\n",
        "        design_diag = TBRMMDiagnostics(\n",
        "            self.data.aggregate_time_series(group_star_trt[k]), self.parameters)\n",
        "        design_diag.x = self.data.aggregate_time_series(group_star_ctl[k])\n",
        "        design_score = TBRMMScore(design_diag)\n",
        "        design = TBRMMDesign(\n",
        "            design_score, group_star_trt[k], group_star_ctl[k],\n",
        "            copy.deepcopy(design_diag))\n",
        "        results.push(0, design)\n",
        "\n",
        "    self._search_results = results\n",
        "    return self.search_results()\n"
      ],
      "metadata": {
        "id": "lR_0Uyrtjthf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select the parameters for the design of the experiment\n",
        "\n",
        "## The minimum detectable iROAS is defined as the value of the true iROAS such\n",
        "## that, given a confidence_level (input) % confidence level for a one-sided\n",
        "## test, gives a power_level (input) % power if the true iROAS is equal to the\n",
        "## minimum detectable iROAS.\n",
        "minimum_detectable_iROAS =  3#@param{type: \"number\"}\n",
        "#@markdown Use an average order value of 1 if the design is based on\n",
        "#@markdown sales/revenue or an actual average order value (e.g. $80) for a\n",
        "#@markdown design based on transactions/footfall/contracts.\n",
        "average_order_value =  1#@param{type: \"number\"}\n",
        "\n",
        "confidence_level = 0.90 #@param {type:\"number\"}\n",
        "power_level = 0.80 #@param {type:\"number\"}\n",
        "experiment_duration_in_weeks = 4 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown List the maximum budget for the experiment e.g. 300000\n",
        "experiment_budget =  300000#@param{type: \"number\"}\n",
        "#@markdown List any alternative budget which you would like to test separated\n",
        "#@markdown by a comma, e.g. 125000, 150000\n",
        "alternative_budget = \"\" #@param{type: \"string\"}\n",
        "additional_budget = [float(re.sub(r\"\\W+\", \"\", x)) for x in\n",
        "                     alternative_budget.split(',') if alternative_budget != \"\"]\n",
        "\n",
        "#@markdown List the days and time periods that you want to exclude separated by\n",
        "#@markdown a comma e.g. 2019/10/10, 2010/10/11, 2018/10/20-2018/11/20.\n",
        "#@markdown The format for time periods is \"YYYY/MM/DD - YYYY/MM/DD\",\n",
        "#@markdown where the two dates specify the start and end date for the period.\n",
        "#@markdown The format for day is \"YYYY/MM/DD\". Leave empty to\n",
        "#@markdown use all days/weeks.\n",
        "day_week_exclude = \"\" #@param {type: \"string\"}\n",
        "day_week_exclude = [] if day_week_exclude == \"\" else [\n",
        "    re.sub(r\"\\s+\", \"\", x) for x in day_week_exclude.split(\",\")\n",
        "]\n",
        "## Find all the days we should exclude from the analysis from the input\n",
        "periods_to_exclude = utils.find_days_to_exclude(day_week_exclude)\n",
        "days_exclude = utils.expand_time_windows(periods_to_exclude)\n",
        "\n",
        "## Additional constraints which will be flagged in red if not met in\n",
        "## the design\n",
        "\n",
        "# upper bound on the minimal detectable relative lift\n",
        "minimum_detectable_lift_in_response_metric = 0.1 * 100\n",
        "# lower bound on the baseline revenue covered by the treatment group\n",
        "minimum_revenue_covered_by_treatment = 0.05 * 100\n",
        "\n",
        "\n",
        "\n",
        "frequency = infer_frequency(geo_level_time_series, 'date', 'geo')\n",
        "if frequency == \"D\":\n",
        "  n_test = experiment_duration_in_weeks * 7\n",
        "  ## Use the most recent ~6 months\n",
        "  n_pretest = 180\n",
        "elif frequency == \"W\":\n",
        "  n_test = experiment_duration_in_weeks\n",
        "  n_pretest = 26\n",
        "\n",
        "## Other constraints/parameters which are hidden to the user\n",
        "\n",
        "## Ratio of avg. control group response / avg. treatment group response must be\n",
        "## between 1/(1+volume_ratio_tolerance) and 1+volume_ratio_tolerance\n",
        "volume_ratio_tolerance = np.inf\n",
        "## Ratio of number of control geos / number treatment geos must be\n",
        "## between 1/(1+geo_ratio_tolerance) and 1+geo_ratio_tolerance\n",
        "geo_ratio_tolerance = np.inf\n",
        "## Constrain on the % of the treatment group response with respect to the\n",
        "## overall response\n",
        "treatment_share_range = (0.0001, 0.9999)\n",
        "## Minimum and maximum number of geos to include in the treatment group\n",
        "treatment_geos_range = (1, num_geos - 1)\n",
        "## Minimum and maximum number of geos to include in the control group\n",
        "control_geos_range = (1, num_geos - 1)\n",
        "## Maximum number of geos to include in the search\n",
        "n_geos_max = num_geos\n",
        "## Maximum number of pretest timepoints to include in the time series for the\n",
        "## purpose of estimating minimum detectable response\n",
        "n_pretest_max = n_pretest\n",
        "## Number of design to store during the exhaustive search\n",
        "n_designs = 3\n",
        "## Maximum assumed treatment-control correlation to use for estimating the MDR\n",
        "rho_max = 0.995\n",
        "## Minimum acceptable Pearson correlation between the treatment and control\n",
        "## time series.\n",
        "min_corr = 0.8\n",
        "## Inverse quantile of the f distribution parameter 'phi' used in the TBR\n",
        "## preanalysis formula.\n",
        "flevel = 0.9\n",
        "\n",
        "budget_range = (0.1, experiment_budget)\n",
        "min_volume_ratio = 1/(1 + volume_ratio_tolerance)\n",
        "max_volume_ratio = 1 + volume_ratio_tolerance\n",
        "\n",
        "tbr_parameters = tbrmmdesignparameters.TBRMMDesignParameters(\n",
        "    n_test=n_test,\n",
        "    iroas=minimum_detectable_iROAS,\n",
        "    volume_ratio_tolerance=volume_ratio_tolerance,\n",
        "    geo_ratio_tolerance=geo_ratio_tolerance,\n",
        "    treatment_share_range=treatment_share_range,\n",
        "    budget_range=budget_range,\n",
        "    treatment_geos_range=treatment_geos_range,\n",
        "    control_geos_range=control_geos_range,\n",
        "    n_geos_max=n_geos_max,\n",
        "    n_pretest_max=n_pretest_max,\n",
        "    n_designs=n_designs,\n",
        "    sig_level=confidence_level,\n",
        "    power_level=power_level,\n",
        "    min_corr=min_corr,\n",
        "    rho_max=rho_max,\n",
        "    flevel=flevel)\n",
        "\n",
        "# remove dates that the user wants to exclude\n",
        "data_for_design = geo_level_time_series[~geo_level_time_series['date']\n",
        "                                        .isin(days_exclude)].copy()\n",
        "tbrclass = tbrmmdata.TBRMMData(df=data_for_design,\n",
        "                               response_column='response',\n",
        "                               geo_eligibility=geo_eligibility)\n",
        "\n",
        "MMclass = TBRMatchedMarkets(data=tbrclass,\n",
        "                                              parameters=tbr_parameters)"
      ],
      "metadata": {
        "id": "ESdTlDD_gHQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WZ9EopaibKRM"
      },
      "outputs": [],
      "source": [
        "#@title Summary of the possible designs\n",
        "\n",
        "max_feasible_number_of_designs = 5 * 10 ** 6\n",
        "\n",
        "if MMclass.count_max_designs() < max_feasible_number_of_designs:\n",
        "  matched_designs = MMclass.exhaustive_search()\n",
        "else:\n",
        "  matched_designs = MMclass.greedy_search()\n",
        "\n",
        "if len(matched_designs) == 0:\n",
        "  raise ValueError(f'{Fore.RED}It wasn\\'t possible to find a design within ' +\n",
        "                   f'the constraint in input or because all the designs, ' +\n",
        "                   f'did not pass one among the AA test, structural break ' +\n",
        "                   f'test, or minimum correlation of 0.8\\n{Style.RESET_ALL}')\n",
        "\n",
        "matched_designs.sort(reverse=True)\n",
        "chosen_design = matched_designs[0]\n",
        "\n",
        "if not chosen_design.score.score.aa_test:\n",
        "  print(f'{Fore.RED}WARNING: the design does not pass the A/A test. ' +\n",
        "        f'We do not recommend to use the proposed design.\\n{Style.RESET_ALL}')\n",
        "\n",
        "if not chosen_design.score.score.bb_test:\n",
        "  print(f'{Fore.RED}WARNING: the design does not pass the Brownian Bridge ' +\n",
        "        f'test. The relationship between treatment/control is ' +\n",
        "        f'not stable over time. We do not recommend to use ' +\n",
        "        f'the proposed design.\\n{Style.RESET_ALL}')\n",
        "\n",
        "if not chosen_design.score.score.dw_test:\n",
        "  print(f'{Fore.RED}WARNING: the design does not pass the Durbin-Watson ' +\n",
        "        f'test. The residuals are autocorrelated. We do not recommend to use ' +\n",
        "        f'the proposed design.\\n{Style.RESET_ALL}')\n",
        "\n",
        "minimum_iroas_aov = minimum_detectable_iROAS / average_order_value\n",
        "minimum_detectable_impact = chosen_design.diag.estimate_required_impact(\n",
        "    chosen_design.diag.corr)\n",
        "\n",
        "optimal_budget = minimum_detectable_impact / minimum_iroas_aov\n",
        "lower_budget = optimal_budget *  0.8\n",
        "upper_budget = optimal_budget * 1.2\n",
        "list_of_budgets = [lower_budget, optimal_budget, upper_budget\n",
        "                  ] + additional_budget\n",
        "\n",
        "first_day = geo_level_time_series[\"date\"].max() - pd.Timedelta(\n",
        "    str(experiment_duration_in_weeks) + \"W\")\n",
        "most_recent_geo_level_time_series = geo_level_time_series[\n",
        "    geo_level_time_series['date'] > first_day]\n",
        "\n",
        "total_response = most_recent_geo_level_time_series[\"response\"].sum()\n",
        "total_spend = most_recent_geo_level_time_series[\"cost\"].sum()\n",
        "chosen_design.treatment_geos = {int(x) for x in chosen_design.treatment_geos}\n",
        "chosen_design.control_geos = {int(x) for x in chosen_design.control_geos}\n",
        "designs = []\n",
        "for budget in list_of_budgets:\n",
        "  baseline = most_recent_geo_level_time_series.loc[\n",
        "      most_recent_geo_level_time_series[\"geo\"].isin(chosen_design.treatment_geos\n",
        "                                                   ), \"response\"].sum()\n",
        "  cost_in_experiment = most_recent_geo_level_time_series.loc[\n",
        "      most_recent_geo_level_time_series[\"geo\"].isin(chosen_design.treatment_geos\n",
        "                                                   ), \"cost\"].sum()\n",
        "  min_detectable_iroas = (\n",
        "      average_order_value * minimum_detectable_impact / budget)\n",
        "  min_detectable_lift = (minimum_detectable_impact * 100 / baseline)\n",
        "  num_treatment_geos = len(chosen_design.treatment_geos)\n",
        "  num_control_geos = len(chosen_design.control_geos)\n",
        "  num_removed_geos = num_geos - num_treatment_geos - num_control_geos\n",
        "  treat_control_removed = (f'{num_treatment_geos}  /  {num_control_geos}  / ' +\n",
        "                           f'{num_removed_geos}')\n",
        "  revenue_covered = 100 * baseline / total_response\n",
        "  proportion_cost_in_experiment = cost_in_experiment / total_spend\n",
        "  national_budget = utils.human_readable_number(\n",
        "      budget / proportion_cost_in_experiment)\n",
        "  designs.append({\n",
        "      \"Budget\": utils.human_readable_number(budget),\n",
        "      \"Minimum detectable iROAS\": f'{min_detectable_iroas:.3}',\n",
        "      \"Minimum detectable lift in response\": f'{min_detectable_lift:.2f} %',\n",
        "      \"Treatment/control/excluded geos\": treat_control_removed,\n",
        "      \"Revenue covered by treatment group\": f'{revenue_covered:.2f} %',\n",
        "      \"Cost/baseline response\": f'{(budget / baseline * 100):.2f} %',\n",
        "      \"Cost if test budget is scaled nationally\": national_budget\n",
        "  })\n",
        "\n",
        "\n",
        "## define function to colorcode rows and cells of the output table\n",
        "def is_optimal_design(row):\n",
        "    \"\"\"Color a row in:\n",
        "    - orange if the minimum detectable iROAS of the corresponding design\n",
        "      is larger than the target\n",
        "    - green if its equal to the target\n",
        "    - beige if it's lower than the target\n",
        "    \"\"\"\n",
        "    if float(row[\"Minimum detectable iROAS\"]) == minimum_detectable_iROAS:\n",
        "          return pd.Series('background-color: lightgreen', row.index)\n",
        "    elif float(row[\"Minimum detectable iROAS\"]) > minimum_detectable_iROAS:\n",
        "          return pd.Series('background-color: orange', row.index)\n",
        "    else:\n",
        "          return pd.Series('background-color: beige', row.index)\n",
        "\n",
        "def flag_warning_lift(val, value):\n",
        "    \"\"\"\n",
        "    Color a cell in red if its value is larger than the value\n",
        "    in input\n",
        "    \"\"\"\n",
        "    color = 'red' if float(val.strip(' %')) > value else 'black'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "def flag_warning_revenue(val, value):\n",
        "    \"\"\"\n",
        "    Color a cell in red if its value is smaller than the value\n",
        "    in input\n",
        "    \"\"\"\n",
        "    color = 'red' if float(val.strip(' %')) < value else 'black'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "\n",
        "## convert the table to a pd.DataFrame and select a subset of columns\n",
        "designs = pd.DataFrame(designs)\n",
        "designs.index.rename(\"Design\", inplace=True)\n",
        "designs = designs[[\"Budget\", \"Minimum detectable iROAS\",\n",
        "                   \"Minimum detectable lift in response\",\n",
        "                   \"Treatment/control/excluded geos\",\n",
        "                   \"Revenue covered by treatment group\",\n",
        "                   \"Cost/baseline response\",\n",
        "                   \"Cost if test budget is scaled nationally\"]]\n",
        "\n",
        "## apply colorcoding to rows and cells of the table\n",
        "designs_table = designs.style.applymap(\n",
        "    flag_warning_lift,\n",
        "    value=minimum_detectable_lift_in_response_metric,\n",
        "    subset=[\"Minimum detectable lift in response\"]).applymap(\n",
        "        flag_warning_revenue,\n",
        "        value=minimum_revenue_covered_by_treatment,\n",
        "        subset=[\"Revenue covered by treatment group\"]).apply(\n",
        "            is_optimal_design, axis=1)\n",
        "\n",
        "designs_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GHh81hAIetrY"
      },
      "outputs": [],
      "source": [
        "#@title Select the design to be used in the experiment\n",
        "#@markdown Select the design using the number as displayed in the table in\n",
        "#@markdown the cell called \"Summary of the possible designs\".\n",
        "\n",
        "selected_design =   1#@param {type:\"integer\"}\n",
        "\n",
        "if selected_design not in designs.index:\n",
        "  raise ValueError(f'the selected design must be one of {designs.index.to_list()}, got {selected_design}')\n",
        "\n",
        "selected_design = int(selected_design)\n",
        "final_design = designs[designs.index == selected_design]\n",
        "selected_budget = final_design[\"Budget\"].values[0]\n",
        "\n",
        "# these are numerical identifier used to denote the two groups\n",
        "group_treatment = GeoAssignment.TREATMENT\n",
        "group_control = GeoAssignment.CONTROL\n",
        "group_excluded = GeoAssignment.EXCLUDED\n",
        "\n",
        "data_for_design.loc[\"assignment\"] = group_excluded\n",
        "data_for_design.loc[data_for_design[\"geo\"].isin(\n",
        "    chosen_design.control_geos), \"assignment\"] = group_control\n",
        "data_for_design.loc[data_for_design[\"geo\"].isin(\n",
        "    chosen_design.treatment_geos), \"assignment\"] = group_treatment\n",
        "\n",
        "# set basic plot parameters\n",
        "chart_width = 600\n",
        "chart_height = 300\n",
        "axis_title_font_size = 16\n",
        "axis_label_font_size = 14\n",
        "title_font_size = 19\n",
        "\n",
        "plot_dict = {\"Response\": {\"colname\": \"response\", \"format\": \"s\"},\n",
        "             \"Ad Spend\": {\"colname\": \"cost\", \"format\": \"s\"}}\n",
        "tb = widgets.TabBar(list(plot_dict.keys()))\n",
        "for k, v in plot_dict.items():\n",
        "  with tb.output_to(k):\n",
        "    # Set y-axis format\n",
        "    format_value = \".1\" if v[\"format\"] == \"s\" else \".2\"\n",
        "    format_string = format_value + v[\"format\"]\n",
        "\n",
        "    # Set dataframe to use for plotting and define y-variable to plot\n",
        "    plot_df = data_for_design[data_for_design[\"assignment\"].isin(\n",
        "        [group_control,\n",
        "        group_treatment])].groupby([\"date\", \"assignment\"],\n",
        "                                    as_index=False)[[\"response\", \"cost\"]].sum()\n",
        "    plot_df[\"assignment\"] = plot_df[\"assignment\"].map({\n",
        "        group_control: \"Control\",\n",
        "        group_treatment: \"Treatment\"\n",
        "    })\n",
        "    y_string = v[\"colname\"] + \":Q\"\n",
        "\n",
        "    # Define how we select based on where the mouse is.\n",
        "    selection = alt.selection_single(\n",
        "        fields=[\"date\"],\n",
        "        nearest=True,\n",
        "        on=\"mouseover\",\n",
        "        empty=\"none\",\n",
        "        clear=\"mouseout\")\n",
        "    bottom_selection = alt.selection_single(\n",
        "        fields=[\"date\"],\n",
        "        nearest=True,\n",
        "        on=\"mouseover\",\n",
        "        empty=\"none\",\n",
        "        clear=\"mouseout\")\n",
        "\n",
        "    # Brush for selecting a location to zoom into on x-axis.\n",
        "    brush = alt.selection(type=\"interval\", encodings=[\"x\"])\n",
        "\n",
        "    # Base chart -- same for top and bottom\n",
        "    base = alt.Chart(plot_df).mark_line().encode(\n",
        "        x=alt.X(\"date:T\", axis=alt.Axis(title=\"\", format=(\"%b %e\")))\n",
        "    )\n",
        "\n",
        "    # Lines for data\n",
        "    lines = base.mark_line().encode(\n",
        "        y=alt.Y(y_string, axis=alt.Axis(title=\" \", format=(format_string)))\n",
        "    )\n",
        "    bottom_lines = lines.encode(alt.X(\"date:T\", scale=alt.Scale(domain=brush)))\n",
        "\n",
        "    # Vertical rule\n",
        "    rule = base.mark_rule().encode(\n",
        "        opacity=alt.condition(selection, alt.value(0.3), alt.value(0)),\n",
        "        tooltip=[\"date:T\", y_string]\n",
        "    ).add_selection(selection)\n",
        "    bottom_rule = base.mark_rule().encode(\n",
        "        opacity=alt.condition(bottom_selection, alt.value(0.3), alt.value(0)),\n",
        "        tooltip=[\"date:T\", y_string]\n",
        "    ).add_selection(bottom_selection)\n",
        "\n",
        "    # Points to denote where the mouse is.\n",
        "    points = lines.mark_point().transform_filter(selection)\n",
        "    bottom_points = bottom_lines.mark_point().transform_filter(bottom_selection)\n",
        "\n",
        "    lines = lines.mark_line().encode(\n",
        "      color=alt.Color(\"assignment\", title=\" \"))\n",
        "    bottom_lines = bottom_lines.mark_line().encode(\n",
        "      color=alt.Color(\"assignment\", title=\" \"))\n",
        "    base_rule = base.transform_pivot(\n",
        "        \"assignment\", value=v[\"colname\"],\n",
        "        groupby=[\"date\"]).mark_rule().encode(tooltip=[\"date:T\"] + [\n",
        "            alt.Tooltip(c, type=\"quantitative\")\n",
        "            for c in plot_df[\"assignment\"].unique()\n",
        "        ])\n",
        "    rule = base_rule.encode(\n",
        "        opacity=alt.condition(selection, alt.value(0.3), alt.value(0))\n",
        "    ).add_selection(selection)\n",
        "    bottom_rule = base_rule.encode(\n",
        "        opacity=alt.condition(bottom_selection, alt.value(0.3), alt.value(0))\n",
        "    ).add_selection(bottom_selection)\n",
        "\n",
        "    scatter_df = plot_df.pivot(\n",
        "        index=\"date\", values=v[\"colname\"], columns=\"assignment\").reset_index()\n",
        "    base = alt.Chart(scatter_df).mark_circle(size=60).encode(\n",
        "        alt.X(\"Control\"),\n",
        "        alt.Y(\"Treatment\"),\n",
        "        tooltip=[\"date\", \"Control\", \"Treatment\"])\n",
        "    regression_line = base.transform_regression(\n",
        "        \"Control\", \"Treatment\", method=\"linear\").mark_line(color=\"red\")\n",
        "    params = alt.Chart(scatter_df).transform_regression(\n",
        "        'Control', 'Treatment', params=True\n",
        "    ).mark_text(align='left', fontSize = 20).encode(\n",
        "        x=alt.value(60),  # pixels from left\n",
        "        y=alt.value(20),  # pixels from top\n",
        "        text='rSquared:N'\n",
        "    )\n",
        "    string_r2 = alt.Chart({'values':[{'x': 30, 'y': 20}]}).mark_text(\n",
        "      text='R^2 = ', fontSize = 20).encode( x=alt.value(30), y=alt.value(20))\n",
        "\n",
        "    # Compile top chart\n",
        "    top_chart = alt.layer(\n",
        "        lines,\n",
        "        points,\n",
        "        rule\n",
        "    ).add_selection(\n",
        "        brush\n",
        "    ).properties(\n",
        "        width=chart_width,\n",
        "        height=chart_height,\n",
        "        title=k\n",
        "    )\n",
        "\n",
        "    # Compile bottom chart\n",
        "    bottom_chart = alt.layer(\n",
        "        bottom_lines,\n",
        "        bottom_rule,\n",
        "        bottom_points\n",
        "    ).properties(\n",
        "        width=chart_width,\n",
        "        height=chart_height\n",
        "    )\n",
        "\n",
        "    # Compile scatterplot\n",
        "    scatter_plot = alt.layer(base, regression_line, params, string_r2).properties(\n",
        "        width=chart_width, height=chart_width, title=k).interactive()\n",
        "    # Combine charts\n",
        "    final_chart = alt.hconcat(\n",
        "        alt.vconcat(\n",
        "            top_chart,\n",
        "            bottom_chart,\n",
        "        ), scatter_plot).resolve_scale(color='independent')\n",
        "\n",
        "    final_chart.configure_axis(\n",
        "        titleFontSize=axis_title_font_size,\n",
        "        labelFontSize=axis_label_font_size\n",
        "    ).configure_title(\n",
        "        fontSize=title_font_size\n",
        "    ).display()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E4qV94M0xyO3"
      },
      "outputs": [],
      "source": [
        "#@title Summary and Results\n",
        "\n",
        "\n",
        "print(\"Data in input:\\n\")\n",
        "print(\"-  {} Geos \\n\".format(\n",
        "    len(geo_level_time_series[\"geo\"].unique())))\n",
        "\n",
        "print(\"Output:\\n\")\n",
        "print(\"The output contains two lists of geos: one for treatment\" +\n",
        "      \" and the other for control\\n\")\n",
        "\n",
        "human_baseline = utils.human_readable_number(baseline)\n",
        "cost_baseline = list_of_budgets[selected_design] * 100 / baseline\n",
        "print('-  {} Geos in treatment and {} geos control\\n'.format(\n",
        "    len(chosen_design.treatment_geos), len(chosen_design.control_geos)))\n",
        "print(\"    Baseline store response: ${} for treatment\\n\".format(human_baseline))\n",
        "print('    Cost/baseline = ${} / ${} ~ {:.3}%\\n'.format(selected_budget,\n",
        "                                                        human_baseline,\n",
        "                                                        cost_baseline))\n",
        "\n",
        "print(f'Minimum detectable iROAS = ' +\n",
        "      f'{final_design[\"Minimum detectable iROAS\"].values[0]}')\n",
        "print(f'Minimum detectable lift in % = ' +\n",
        "      f'{final_design[\"Minimum detectable lift in response\"].values[0]}')\n",
        "\n",
        "print(f\"The design has Power {100 * power_level:.3}+% with Type-I error \" +\n",
        "      f\"{100 *(1 - confidence_level):.3}% for testing H0: iROAS=0 vs \" +\n",
        "      f\"H1: iROAS >= {final_design['Minimum detectable iROAS'].values[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UnBtlmv10THH"
      },
      "outputs": [],
      "source": [
        "#@title Report stores for treatment and control separately and write to trix\n",
        "\n",
        "#@markdown ###Insert the name google sheets in which we will save the data.\n",
        "#@markdown The trix contains 4 worksheets, named:\n",
        "#@markdown * \"pretest data\", containing the geo level time series;\n",
        "#@markdown * \"geopairs\", containing the pairs of geos and their assignment.\n",
        "#@markdown * \"treatment geos\", contains the list of geos in the treatment;\n",
        "#@markdown * \"control geos\", contains the geos in the control groups.\n",
        "Client_Name = \"TBRMM_Client_Name\" #@param {type:\"string\"}\n",
        "filename_design = Client_Name + \"_design.csv\" #@param {type:\"string\"}\n",
        "\n",
        "design_data = geo_level_time_series.copy()\n",
        "\n",
        "design_data[\"assignment\"] = \"Excluded\"\n",
        "design_data.loc[design_data[\"geo\"].isin(\n",
        "    chosen_design.control_geos), \"assignment\"] = \"Control\"\n",
        "design_data.loc[design_data[\"geo\"].isin(\n",
        "    chosen_design.treatment_geos), \"assignment\"] = \"Treatment\"\n",
        "\n",
        "design_data[\"removed\"] = False\n",
        "design_data.loc[design_data[\"date\"].isin(days_exclude), \"removed\"] = True\n",
        "\n",
        "tmp_parameters = {\n",
        "    \"minimum_detectable_iROAS\": minimum_detectable_iROAS,\n",
        "    \"average_order_value\": average_order_value,\n",
        "    \"confidence_level\": confidence_level,\n",
        "    \"power_level\": power_level,\n",
        "    \"experiment_duration_in_weeks\": experiment_duration_in_weeks,\n",
        "    \"experiment_budget\": experiment_budget,\n",
        "    \"alternative_budget\": alternative_budget,\n",
        "    \"day_week_exclude\": \", \".join(day_week_exclude),\n",
        "    \"selected_design\": selected_design,\n",
        "}\n",
        "\n",
        "parameters = {\"parameter\": list(tmp_parameters.keys()),\n",
        "              \"value\": list(tmp_parameters.values())}\n",
        "\n",
        "\n",
        "sh = gc.create(filename_design)\n",
        "wid = sh.add_worksheet(\"pretest data\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, design_data)\n",
        "wid = sh.add_worksheet(\"treatment geos\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, pd.DataFrame({\"geo\": list(chosen_design.treatment_geos)}))\n",
        "wid = sh.add_worksheet(\"control geos\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, pd.DataFrame({\"geo\": list(chosen_design.control_geos)}))\n",
        "wid = sh.add_worksheet(\"parameters used in the design\", rows=1, cols=1)\n",
        "set_with_dataframe(wid, pd.DataFrame(parameters))\n",
        "out = sh.del_worksheet(sh.sheet1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRObTJT_YA52"
      },
      "source": [
        "# Appendix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ufG6Clwf4ZuV"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Design Colab For TBR using Matched Markets.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}